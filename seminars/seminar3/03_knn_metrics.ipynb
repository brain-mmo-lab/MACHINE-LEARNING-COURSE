{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5361d83-517a-4b4b-8cd7-e5242fdd7338",
   "metadata": {},
   "source": [
    "# Семинар 3. KNN, метрики качества.\n",
    "\n",
    "## Метрические алгоритмы. KNN.\n",
    "\n",
    "Метрические алгоритмы - класс алгоритмов, анализирующих расстояния:\n",
    "\n",
    "$$\\rho(x, x_1), \\rho(x, x_2), ... , \\rho(x, x_m)$$\n",
    "\n",
    "Примеры подобных алгоритмов:\n",
    "\n",
    "- Nearest Centroids Algorithm\n",
    "- KNN\n",
    "- __K-means__ (познакомитесь на 6 семинаре)\n",
    "\n",
    "### Nearest Centroids Algorithm\n",
    "\n",
    "Решение задачи классификации\n",
    "\n",
    "$$\\mathbb{Y} = \\{1, 2, ... , l\\}, \\ \\ x_i \\in \\mathbb{R}^n$$\n",
    "\n",
    "- построение центроидов\n",
    "\n",
    "  $$c_j = \\frac{1}{|\\{ i: y_i = j \\}|} \\sum_{i: y_i = j} x_i$$\n",
    "\n",
    "- предсказания\n",
    "\n",
    "  $$a(x) = \\arg \\min_j \\rho(x, c_j) $$\n",
    "\n",
    "  - в качестве предсказания выдаем класс, соответствующий ближайшему центроиду\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/k_means.png\" width=\"650px\">\n",
    "</div>\n",
    "\n",
    "$\\newline$\n",
    "\n",
    "- Особенности:\n",
    "    - храним только центроиды\n",
    "    - простая реализация\n",
    "    - размер модели: $l \\times n$\n",
    "    - очень простой алгоритм\n",
    " \n",
    "### Подход основанный на близости\n",
    "\n",
    "Пусть $U(x)$ - окрестность точки $x$.\n",
    "\n",
    "- классификация\n",
    "\n",
    "  $$a(x) = \\text{mode} (y_i | x_i \\in U(x))$$\n",
    "\n",
    "- регрессия\n",
    "\n",
    "  $$a(x) = \\text{mean} (y_i | x_i \\in U(x))$$\n",
    "\n",
    "Формализуем понятие окрестности:\n",
    "### KNN (K Nearest Neighbor)\n",
    "\n",
    "- Пусть $\\mathbb{X}$ - метрическое пространство с метрикой $\\rho$ и нумерация объектов такая, что \n",
    "\n",
    "$$\\rho(x, x_1) \\le ... \\le \\rho(x, x_m)$$\n",
    "\n",
    "   - Тогда окрестностью $x$ будет: $U_k(x) = \\{x_1, x_2, ... x_k \\}$\n",
    "\n",
    "$\\newline$\n",
    "\n",
    "- Особенности:\n",
    "    - нет обучения, работа алгоритм - просмотреть всю выборку и подсчитать расстояния - _lazy learning_\n",
    "    - требуется подобрать гиперпараметры:\n",
    "        - $k$ - число ближайших соседей для предсказания\n",
    "        - 'метрика': $\\mathbf{L_1}$, $\\mathbf{L_2}$, $\\mathbf{L_{\\infty}}$, $\\mathbf{L_p}$, $cosine\\_sim$, ...\n",
    "        - весовая схема\n",
    "    - размер модели: $m \\times n$\n",
    "    - все еще довольно простой алгоритм\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/knn.png\" width=\"650px\">\n",
    "</div>\n",
    "\n",
    "__Вопрос__: Чему равна ошибка алгоритма 1-NN на обучающей выборке?\n",
    "\n",
    "### Весовое обобщение\n",
    "\n",
    "Рассмотрим на примере задачи классификации:\n",
    "\n",
    "$$a(x) = \\text{mode} (y_i | x_i \\in U(x)) = \\arg \\max_{y \\in \\mathbb{Y}} \\sum_{t=1}^k \\mathbb{I}[y_{x_t} = y] \\Rightarrow$$\n",
    "\n",
    "$$\\Rightarrow a(x) = \\arg \\max_{y \\in \\mathbb{Y}} \\sum_{t=1}^m \\mathbb{I}[y_{x_t} = y] w(x_t, x)$$\n",
    "\n",
    "Весовые схемы:\n",
    "  - $w(x_t, x) = \\mathbb{I}[t = 1]$\n",
    "  - $w(x_t, x) = \\mathbb{I}[t \\le k]$\n",
    "  - $w(x_t, x) = \\mathbb{I}[t \\le k] q^t$, где $q < 1$;  $\\ \\ \\ k$ экспоненциально взвешенных ближайших соседей\n",
    "  - [метод парзеновского окна фиксированной/переменной ширины](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BF%D0%B0%D1%80%D0%B7%D0%B5%D0%BD%D0%BE%D0%B2%D1%81%D0%BA%D0%BE%D0%B3%D0%BE_%D0%BE%D0%BA%D0%BD%D0%B0)\n",
    "  - ...\n",
    "\n",
    "Для задачи регрессии в общем виде формула имеет следующий вид:\n",
    "\n",
    "$$a(x) = \\frac{\\sum_{t=1}^{k} w_t y(x_t)}{\\sum_{t=1}^{k} w_t}$$\n",
    "\n",
    "Пример взвешенной схемы в задаче регрессии: [Регрессия Надарая-Ватсона](http://www.machinelearning.ru/wiki/index.php?title=%D0%9E%D1%86%D0%B5%D0%BD%D0%BA%D0%B0_%D0%9D%D0%B0%D0%B4%D0%B0%D1%80%D0%B0%D1%8F-%D0%92%D0%B0%D1%82%D1%81%D0%BE%D0%BD%D0%B0)\n",
    "\n",
    "### Метрики расстояния\n",
    "\n",
    "__Метрика__ на $\\mathbb{X}$ - это функция $\\rho(x, z): \\mathbb{X} \\times \\mathbb{X} \\rightarrow \\mathbb{R}$:\n",
    " - $\\rho(x, z) \\ge 0$\n",
    " - $\\rho(x, z) = 0 \\Leftrightarrow x = z$\n",
    " - $\\rho(x, z) = \\rho(z, x)$\n",
    " - $\\rho(x, z) + \\rho(z, y) \\ge \\rho(x, y)$\n",
    "\n",
    "#### Примеры метрик:\n",
    "\n",
    "- Евклидова ( $\\mathbf{L}_2$ )\n",
    "  $$\\rho(x, z) =  \\|x - z \\|_2 = \\sqrt{ \\sum_{i = 1}^n (x_i - z_i)^2}$$\n",
    "\n",
    "- Манхэттена ( $\\mathbf{L}_1$ )\n",
    "  $$\\rho(x, z) = \\|x - z \\|_1 = \\sum_{i = 1}^n |x_i - z_i|$$\n",
    "\n",
    "- Чебышева ( $\\mathbf{L}_{\\infty}$ )\n",
    "  $$\\rho(x, z) = \\|x - z \\|_{\\infty} = \\max_i |x_i - z_i|$$\n",
    "\n",
    "- Минковского ( $\\mathbf{L}_p$ )\n",
    "  $$\\rho(x, z) =  \\|x - z \\|_p = \\left( \\sum_{i = 1}^n |x_i - z_i|^p \\right)^{1/p} $$\n",
    "\n",
    "\n",
    "В качестве метрик в методе ближайших соседей используются не только формальные метрики, но и функции расстояния:\n",
    "\n",
    "- косинусная мера сходства(_cosine similarity_)\n",
    "  $$1 - \\cos (x, z) = 1 - \\frac{x^T z}{ \\| x \\| \\| z \\|} = 1 - \\frac{\\sum_{i=1}^n x_i z_i}{\\sqrt{\\sum_{i=1}^n x_i^2} \\sqrt{\\sum_{i=1}^n z_i^2}}$$\n",
    "- [Canberra distance](https://en.wikipedia.org/wiki/Canberra_distance)\n",
    "- [расстояние Хэмминга](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D1%81%D1%82%D0%BE%D1%8F%D0%BD%D0%B8%D0%B5_%D0%A5%D1%8D%D0%BC%D0%BC%D0%B8%D0%BD%D0%B3%D0%B0)\n",
    "- [расстояние Джаккарда](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D1%8D%D1%84%D1%84%D0%B8%D1%86%D0%B8%D0%B5%D0%BD%D1%82_%D0%96%D0%B0%D0%BA%D0%BA%D0%B0%D1%80%D0%B0)\n",
    "- [DTW](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%B4%D0%B8%D0%BD%D0%B0%D0%BC%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B9_%D1%82%D1%80%D0%B0%D0%BD%D1%81%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%B8_%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D0%BE%D0%B9_%D1%88%D0%BA%D0%B0%D0%BB%D1%8B)\n",
    "- [Расстояние Левенштейна](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D1%81%D1%82%D0%BE%D1%8F%D0%BD%D0%B8%D0%B5_%D0%9B%D0%B5%D0%B2%D0%B5%D0%BD%D1%88%D1%82%D0%B5%D0%B9%D0%BD%D0%B0)\n",
    "- ...\n",
    "\n",
    "### Напоминание\n",
    "\n",
    "__Метрические методы существенно зависят от масштаба и однородности признаков. Стоит учитывать это во время подготовки данных к обучению.__\n",
    "\n",
    "\n",
    "__Проклятие размерности__ — проблема, связанная с экспоненциальным возрастанием количества данных из-за увеличения размерности пространства.\n",
    "\n",
    "Рассмотрим геометрический пример. Для того, чтобы добиться равномерного покрытия отрезка $[0, 1]$ будет достаточно взять $100$ точек. В то же время для равномерного покрытия $10$-мерного куба потребуется $100^{10} = 10^{20}$ точек. То есть по сравнению с одномерным кубом необходимо в $10^{18}$ больше точек.\n",
    "\n",
    "Теперь рассмотрим еще один интересный сюжет, связанный с проклятием размерности и метрическими алгоритмами: \n",
    "Будем вычислять объем шара радиуса $r$ в $\\mathbb{R}^n$:\n",
    "\n",
    "  - $n = 1$: $V_1(r) = 2r$\n",
    "  - $n = 2$: $V_2(r) = \\pi r^2$\n",
    "  - $n = 3$: $V_3(r) = \\dfrac{4}{3} \\pi r^3$\n",
    "  - ...\n",
    "  - $n$: $V_n(r) = \\dfrac{\\pi^{n/2}}{\\Gamma(n/2 + 1)} r^n$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/CD.png\" width=\"550px\">\n",
    "</div>\n",
    "\n",
    "_Можно заметить, что весь объем шара сосредоточен на поверхностном слое:_\n",
    "\n",
    "$$\\dfrac{V_n(r+\\varepsilon)}{V_n(r)} = \\dfrac{(r + \\varepsilon)^n}{r^n} \\underset{n \\rightarrow + \\infty}{\\longrightarrow} + \\infty$$\n",
    "\n",
    "То есть в рассмотренном нами методе KNN, скорее всего все соседи будут лежать с краю.\n",
    "\n",
    "Особенности:\n",
    "  - трудоемкость вычислений\n",
    "  - необходимость хранения огромного количества данных\n",
    "  - большое количество признаков при относительно небольшом количестве данных ведет к переобучению\n",
    "  - в метрических классификаторах расстояния обычно вычисляются как средний модуль разностей по всем признакам. Согласно Закону Больших Чисел, сумма $n$ слагаемых стремится в некоторому фиксированному пределу при $n \\rightarrow + \\infty$. Таким образом, расстояния во всех парах объектов стремятся к одному и тому же значению, а значит, становятся неинформативными.\n",
    "\n",
    "Бороться с этим явлением можно с помощью таких подходов, как отбор признаков, метод главных компонент(PCA) (с ним вы познакомитесь на одном из ближайших семинаров) и другие способы снижения размерности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4dc9c4-924a-4f3c-a391-b2332cae60e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Метрики качества\n",
    "\n",
    "Мы уже научились ставить задачи машинного обучения, а также познакомились с некоторыми алгоритмами, которые позволяют строить модели, аппроксимирующие зависимости между признаковым описанием и целевой переменной, но как понять на сколько качественно мы это делаем? Как понять, какая модель лучше справляется с той или иной задачей?\n",
    "\n",
    "Если вы учавствовали в соревнования по машинному обучению(см. [kaggle](https://www.kaggle.com/)), то в них метрика качества определяется за вас организаторами соревнований, в реальной жизни вам самим предстоит разбираться с тем, что такое лучшая модель.\n",
    "\n",
    "Так, одна из задач дата-саентиста подобрать критерий, который поможет выбрать лучшую модель.\n",
    "\n",
    "На лекциях вы уже познакомились с понятием функции ошибки и эмпирического риска.\n",
    "\n",
    "__Loss function__ ($L(a,x): \\mathbb{X} \\rightarrow \\mathbb{R}$) - отображение, показывающее 'стоимость' ошибки.\n",
    "\n",
    "__Эмпирический риск__ - средняя величина ошибки на обучающей выборке.\n",
    "$$Q(a, X^m) = \\frac{1}{m} \\sum_{x \\in X^m} L(a, x)$$\n",
    "\n",
    "__Важно помнить, что функция потерь/эмпирический риск $\\neq$ метрика качества.__\n",
    "\n",
    "- _Метрика качества_ внешний критерий, который не зависит от параметров модели, а отображает качество решения исходной задачи(предсказанных меток).\n",
    "- _Функция потерь_ появляется в момент, когда задача построения модели сводится к задаче оптимизации для получения наилучший параметров. Зачастую эта функция должна обладать некоторыми свойствами, например, дифференцируемостью.\n",
    "\n",
    "Однако в некоторых случаях метрика качества может совпадать с функцией потерь. Так в задаче регрессии [$MSE$](https://en.wikipedia.org/wiki/Mean_squared_error) может выступать, как в роли метрики качества, так и в роли функции потерь.\n",
    "\n",
    "### Задача бинарной классификации: I\n",
    "\n",
    "#### [Accuracy](https://scikit-learn.org/dev/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "- доля корректно предсказанных примеров\n",
    "$$accuracy(y, \\hat{y}) = \\frac{1}{m} \\sum_{i=1}^m \\mathbb{I}[a(x_i) = y_i]$$\n",
    "- сопряженная ей метрика - доля ошибочных классификаций(__error rate__)\n",
    "$$ErrorRate = 1 - accuracy$$\n",
    "\n",
    "Accuracy имеет $2$ существенных недостатка:\n",
    " - не учитывает дисбаланс классов\n",
    "   - Предположим, что на производство поступило $110$ станков, из которых $100$ исправны и $10$ неисправны. Также в нашем распоряжении имеется модель, которая предсказывает исправность станка. Из $100$ исправных станков $90$ классификатор определил верно, а среди $10$ неисправлных, верно определено $5$. Таким образом,\n",
    "     $$accuracy = \\frac{1}{110} (90 + 5) = \\frac{95}{110} = 0.86$$\n",
    "   - Если же мы будем использовать классификатор, который всегда будет выдавать тождественный результат - \"Исправен\", то доля правильных ответов будет:\n",
    "     $$accuracy = \\frac{100}{110} = 0.91$$\n",
    "\n",
    " - не учитывает цену ошибки для объектов разных классов\n",
    "    - В медицинской диагностике ложное предсказание для здорового пациента приведет к повторному обследованию, а в случае ложного предсказания для нездорового пациента может привести к печальным последствиям\n",
    "  \n",
    "Для того чтобы учитывать для объектов разных классов перейдем к рассмотрению следующего показателя качества алгоритма - матрица ошибок(Confusion matrix)\n",
    "\n",
    "#### [Confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "\n",
    "Чтобы познакомиться с матрицей ошибок, разберемся какие предсказания может давать классификатор в бинарном случае:\n",
    "- верно предсказываем положительную метку. Такие объекты обозначаются, как **true positive (TP)**. True — потому что предсказали мы правильно, а positive — потому что предсказали положительную метку\n",
    "- предсказываем положительную метку, но ошибаемся в своём предсказании — **false positive (FP)**. False, потому что предсказание было неправильным\n",
    "- предсказываем отрицательную метку, но ошибаемся — **false negative (FN)**\n",
    "- верно предсказываем отрицательную метку — **true negative (TN)**\n",
    "\n",
    "Для удобства все эти 4 числа изображают в виде таблицы, которую называют **confusion matrix**:\n",
    "\n",
    "| <!---  ---> | $y = 1$ | $y = 0$ |\n",
    "|--------------|--------------|--------------|\n",
    "| $\\hat{y} = 1$ | True Positive (TP)   | False Positive (FP) |\n",
    "| $\\hat{y} = 0$ | False Negative (FN)   | True Negative (TN) |\n",
    "\n",
    "Таким образом, мы можем совершить $2$ типа ошибок: $FP$ и $FN$. Они также называются ошибками I и II рода.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/error_type.jpeg\" width=\"650px\">\n",
    "</div>\n",
    "\n",
    "Матрица ошибок не является каким-то показателем качества, хотя мы и стремимся максимизировать главную диагональ и минимизировать недиагональные элементы(однако на матрицах не задан порядок, а потому сравнить $2$ произвольные матрицы мы не можем), она дает нам инструмент для анализа ошибок.\n",
    "\n",
    "Также с помощью введенных обозначений мы можем переписать формулы для $accuracy$ и $error\\_rate$:\n",
    "$$accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "$$ErrorRate = \\frac{FP + FN}{TP + TN + FP + FN}$$\n",
    "\n",
    "Что показывает нам, что $accuracy$ оперирует только верными предсказаниями, а $ErrorRate$ неверными. При этом, как мы уже посмотрели в случае дисбаланса классов $accuracy$ может быть обманчивой, это же касается и $ErrorRate$.\n",
    "\n",
    "__Accuracy__ имеет смысл применять, когда отсутствует сильный дисбаланс классов и классы имеют одинаковое значение.\n",
    "\n",
    "Зачастую класс, который представляет для нас интерес обозначается \"положительным\", верные предсказания на нем $TP$, поэтому в случае ассиметрии классов, можно использовать метрики, которые ориентируются на $TP$ и не учитывают $TN$. \n",
    "\n",
    "#### [Precision (точность)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)\n",
    "\n",
    "- Доля правильно предсказанных положительных объектов среди всех объектов, предсказанных положительными.\n",
    "\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "\n",
    "- Чем меньше ложноположительных срабатываний будет допускать алгоритм, тем больше будет значение $Precision$.\n",
    "\n",
    "#### [Recall (полнота)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n",
    "\n",
    "- Доля правильно предсказанных положительных объектов среди всех объектов, являющихся положительными.\n",
    "\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "- Чем меньше ложноотрицательных срабатываний будет допускать алгоритм, тем больше будет значение $Recall$.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/prec_rec.png\" width=\"250px\">\n",
    "</div>\n",
    "\n",
    "В задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить.\n",
    "\n",
    "__Precision__ и __Recall__ не зависят от баланса классов, а потому применимы в условиях несбалансированных выборок. Однако на практике стоит задача найти баланс между парой $Precision-Recall$, одним из популярных способов их комбинации является $F_1$ мера - среднее гармоническое $Precision$ и $Recall$.\n",
    "\n",
    "#### [$F_1$ - мера](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
    "\n",
    "$$F_1 = \\frac{2}{\\frac{1}{Recall} + \\frac{1}{Precision}} = 2 \\frac{Recall \\cdot Precision}{Recall + Precision}$$\n",
    "\n",
    "$F_1$-мера предполагает одинаковый приоритет у $Recall$ и $Precision$. У нее есть обобщение, которое позволяет балансировать между важностью $Recall$ и $Precision$.\n",
    "\n",
    "#### [$F_{\\beta}$ - мера](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html)\n",
    "\n",
    "$$F_{\\beta} =  (\\beta^2 + 1) \\frac{Recall \\cdot Precision}{Recall + \\beta^2 Precision}$$\n",
    "\n",
    "### Задача бинарной классификации: II\n",
    "\n",
    "Многие модели МО, решающие задачу бинарной классификации, устроены таким образом, что разделают объекты по классам на основе некоторого порога:\n",
    "\n",
    "$$f(x, w, w_0) = \\mathbb{I}[g(x, w) > w_0]$$\n",
    "\n",
    "В частности простейший линейный классификатор будет устроен следующим образом:\n",
    "\n",
    "$$f(x, w, w_0) = \\mathbb{I}[x^Tw > 0]$$\n",
    "\n",
    "Однако такое преобразование приводит к потере информации, поскольку результат бинарной классификации не показывает, насколько выше или ниже значения порога отсечения. Нужно учитывать, что в зависимости от порога мы будем получать разные предсказания и разное качество на отложенной выборке. Как в этом случае оценивать качество модели?\n",
    "\n",
    "Рассмотрим $2$ величины, которые монотонно не убывают при уменьшении порога:\n",
    "\n",
    "$$TruePositiveRate = TPR = \\frac{TP}{TP + FN} =^* Recall$$\n",
    "\n",
    "$$FalsePositiveRate = FPR = \\frac{FP}{FP + TN}$$\n",
    "\n",
    "__TruePositiveRate__ ( $TPR$ ) - доля положительных объектов, правильно предсказанных положительными(полнота).\n",
    "\n",
    "__FalsePositiveRate__ ( $FPR$ ) - доля отрицательных объектов, неправильно предсказанных положительными.\n",
    "\n",
    "Кривая, построенная в координатах $ \\ TPR( \\ FPR \\ )$ при варьировании порога, называется [__ROC-кривой__](http://www.machinelearning.ru/wiki/index.php?title=ROC-%D0%BA%D1%80%D0%B8%D0%B2%D0%B0%D1%8F). Каждая точка на графике соответствует выбору некоторого порога. Она проходит из точки $(0,0)$, соответствующей максимальному значению $w_0$, в точку $(1,1)$, соответствующую минимальному значению $w_0$.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/ROC.png\" width=\"650px\">\n",
    "</div>\n",
    "\n",
    "Чем выше лежит кривая, тем лучше качество классификации. ROC-кривая может быть вычислена по любой выборке. Однако ROC-кривая, вычисленная по обучающей выборке, является оптимистично смещённой влево-вверх вследствие переобучения. Величину этого смещения предсказать довольно трудно, поэтому на практике ROC-кривую всегда оценивают по независимой тестовой выборке.\n",
    "\n",
    "#### [ROC-AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
    "\n",
    "Площадь под ROC-кривой AUC (Area Under Curve) является агрегированной характеристикой качества классификации, не зависящей от соотношения цен ошибок. Чем больше значение AUC, тем «лучше» модель классификации.\n",
    "\n",
    "__AUC ROC__ равен доле пар объектов вида (объект класса 1, объект класса 0), которые алгоритм верно упорядочил. Может быть интерпретирован как вероятность того, что случайно выбранный положительный объект будет проранжирован классификатором выше (будет иметь более высокую вероятность быть 'положительным'), чем случайно выбранный 'отрицательный' объект. Таким образом, в любой задаче, где нам важна не метка сама по себе, а правильный порядок на объектах, имеет смысл применять AUC.\n",
    "\n",
    "Подробнее о ROC-AUC, а также о том, как ее строить, настоятельно советуем ознакомиться в [__материалах А.Г. Дьяконова__](https://alexanderdyakonov.wordpress.com/2017/07/28/auc-roc-%D0%BF%D0%BB%D0%BE%D1%89%D0%B0%D0%B4%D1%8C-%D0%BF%D0%BE%D0%B4-%D0%BA%D1%80%D0%B8%D0%B2%D0%BE%D0%B9-%D0%BE%D1%88%D0%B8%D0%B1%D0%BE%D0%BA/). [Задачи для проверки cебя.](https://alexanderdyakonov.wordpress.com/2015/10/09/%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%BA%D0%B8-%D0%BF%D1%80%D0%BE-auc-roc/)\n",
    "\n",
    "Рассмотрим задачу выделения математических статей из множества научных статей. Допустим, что всего имеется $1010$ статей, из которых лишь $10$ относятся к математике. Если нам удастся построить алгоритм $a(x)$, идеально решающий задачу, то его $TPR$ будет равен единице, а $FPR$ — нулю. Рассмотрим теперь 'плохой' алгоритм, дающий положительный ответ на $9$ математических и $50$ нематематических статьях. Такой алгоритм совершенно бесполезен, но при этом имеет $TPR = \\frac{9}{10} = 0.95$ и $FPR = \\frac{50}{1000} = 0.05$, что крайне близко к показателям идеального алгоритма. Таким образом, если положительный класс существенно меньше по размеру, то AUC-ROC может давать неадекватную оценку качества работы алгоритма, поскольку измеряет долю неверно принятых объектов относительно общего числа отрицательных. \n",
    "\n",
    "#### Precison-recall (PR) кривая. [AUC-PR](https://scikit-learn.org/dev/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score)\n",
    "\n",
    "Избавиться от указанной проблемы с несбалансированными классами можно, перейдя от ROC-кривой к PR-кривой. Она определяется аналогично ROC-кривой, только по осям откладываются не FPR и TPR, а полнота($recall$) (по оси абсцисс) и точность($precision$) (по оси ординат). Критерием качества семейства алгоритмов выступает площадь под PR-кривой (Area Under the Curve — AUC-PR).\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"src/PR.png\" width=\"620px\">\n",
    "</div>\n",
    "\n",
    "Рассмотрим среднее значение точности (оно равно площади под кривой точность-полнота):\n",
    "\n",
    "$$AP = \\int_0^1 p(r)dr$$\n",
    "\n",
    "Получим показатель эффективности, который называется average precision.\n",
    "\n",
    "\n",
    "### Многоклассовая классификация\n",
    "\n",
    "Если классов становится больше двух, расчёт метрик усложняется. Если задача классификации на $K$ классов ставится как $K$ задач об отделении класса $i$ от остальных $(i = 1,..., K)$, то для каждой из них можно посчитать свою матрицу ошибок. Затем есть два варианта получения итогового значения метрики из K матриц ошибок:\n",
    "\n",
    " - Усредняем элементы матрицы ошибок $(TP, FP, TN, FN)$ между бинарными классификаторами, например $TP=\\frac{1}{K}\\sum_{i=1}^K TP_i$. Затем по одной усреднённой матрице ошибок считаем $Precision$, $Recall$, $F$-меру. Это называют __микроусреднением__.\n",
    " - Считаем $Precision$, $Recall$ для каждого классификатора отдельно, а потом усредняем. Это называют __макроусреднением__.\n",
    "\n",
    "__Важно__: Порядок усреднения влияет на результат в случае дисбаланса классов.\n",
    "\n",
    "\n",
    "### Регрессия\n",
    "\n",
    "В задаче регрессии нас зачастую интересует величина невязки: $e_i = a(x_i) - y_i$, которую необходимо агрегировать по набору данных.\n",
    "\n",
    "#### [(R)MSE](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.mean_squared_error.html)\n",
    "\n",
    "Одна из самых популряных метрик, которая также часто используется, как функция потерь для многих моделей - это $MSE$.\n",
    "\n",
    "$$MSE(y, \\hat{y}) = \\frac{1}{m} \\sum_{i=1}^m (y_i - a(x_i))^2 $$\n",
    "\n",
    "Чтобы показатель эффективности MSE имел размерность исходных данных, иногда из него извлекают квадратный корень и получают показатель эффективности RMSE.\n",
    "\n",
    "$$RMSE(y, \\hat{y}) = \\sqrt{\\frac{1}{m} \\sum_{i=1}^m (y_i - a(x_i))^2 } $$\n",
    "\n",
    "MSE неограничен сверху, и может быть нелегко понять, насколько «хорошим» или «плохим» является то или иное его значение.\n",
    "\n",
    "Если большие ошибки для нас действительно неприемлемы, то квадратичный штраф за них — очень полезное свойство (и его даже можно усиливать, повышая степень, в которую мы возводим ошибку на объекте). Однако если в наших тестовых данных присутствуют выбросы, то нам будет сложно объективно сравнить модели между собой: ошибки на выбросах будет маскировать различия в ошибках на основном множестве объектов.\n",
    "\n",
    "#### [$R^2$ (Коэффициент детерминации)](https://scikit-learn.org/dev/modules/generated/sklearn.metrics.r2_score.html)\n",
    "\n",
    "Коэффициент детерминации - это доля дисперсии зависимой переменной, объясняемая рассматриваемой моделью.\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum_{i=1}^{m} (y_i - a(x_i))^2}{\\sum_{i=1}^{m} (y_i - \\overline{y})^2} = 1 - \\frac{\\sigma^2}{\\sigma_y^2}$$\n",
    "\n",
    "где $\\sigma^2$ - условная (по признакам $x$) дисперсия зависимой переменной.\n",
    "\n",
    "Фактически, данная мера качества — это нормированная среднеквадратичная ошибка. Если она близка к единице, то модель хорошо объясняет данные, если же она близка к нулю, то прогнозы сопоставимы по качеству с константным предсказанием. \n",
    "\n",
    "#### [MAE](https://scikit-learn.org/dev/modules/generated/sklearn.metrics.mean_absolute_error.html)\n",
    "\n",
    "Использовать $RMSE$ для сравнения моделей на выборках с большим количеством выбросов может быть неудобно. В таких случаях прибегают к также знакомой вам в качестве функции потери метрике $MAE$ (mean absolute error):\n",
    "\n",
    "$$MAE(y, \\hat{y}) = \\frac{1}{m} \\sum_{i=1}^{m} | y_i - a(x_i) |  $$\n",
    "\n",
    "#### [MAPE](https://scikit-learn.org/dev/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html)\n",
    "\n",
    "Это коэффициент, не имеющий размерности, с очень простой интерпретацией. Его можно измерять в долях или процентах. Если у вас получилось, например, что MAPE=11.4%, то это говорит о том, что ошибка составила 11,4% от фактических значений. Основная проблема данной ошибки — нестабильность.\n",
    "\n",
    "$$ MAPE(y, \\hat{y}) = \\frac{1}{m} \\sum_{i=1}^m \\frac{|y_i - a(x_i)|}{|y_i|} $$\n",
    "\n",
    "#### SMAPE\n",
    "\n",
    "Symmetric MAPE\n",
    "\n",
    "$$ SMAPE(y, \\hat{y}) = \\frac{1}{m} \\sum_{i=1}^m \\frac{2 |y_i - a(x_i)|}{y_i + a(x_i)} $$\n",
    "\n",
    "#### WAPE\n",
    "\n",
    "$$ WAPE(y, \\hat{y}) = \\frac{\\sum_{i=1}^m | y_i - a(x_i) |}{\\sum_{i=1}^m | y_i | } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d55a44-2ec9-453e-8326-89ddaf9ea561",
   "metadata": {},
   "source": [
    "## Ссылки\n",
    "\n",
    "- [Метрические алгоритмы](https://github.com/Dyakonov/MLDM/blob/master/2019/AMD06_metric_18.pdf)\n",
    "- [Метрики в задачах машинного обучения](https://habr.com/ru/companies/ods/articles/328372/)\n",
    "- [Метрики классификации и регрессии](https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii)\n",
    "- [AUC ROC (площадь под кривой ошибок)](https://alexanderdyakonov.wordpress.com/2017/07/28/auc-roc-%D0%BF%D0%BB%D0%BE%D1%89%D0%B0%D0%B4%D1%8C-%D0%BF%D0%BE%D0%B4-%D0%BA%D1%80%D0%B8%D0%B2%D0%BE%D0%B9-%D0%BE%D1%88%D0%B8%D0%B1%D0%BE%D0%BA/)\n",
    "- [Метрики качества. Часть 1. Функции ошибки в задаче регрессии](https://github.com/Dyakonov/PZAD/blob/master/2020/PZAD2020_031err_regression_10n.pdf)\n",
    "- [Метрики качества. Часть 2. Чёткая бинарная классификации](https://github.com/Dyakonov/PZAD/blob/master/2020/PZAD2020_032err_classification_20n.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
